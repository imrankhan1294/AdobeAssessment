{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 3.0\n%worker_type G.1X\n%number_of_workers 5\n\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.0 \nCurrent idle_timeout is 2800 minutes.\nidle_timeout has been set to 2880 minutes.\nSetting Glue version to: 3.0\nPrevious worker type: G.1X\nSetting new worker type to: G.1X\nPrevious number of workers: 5\nSetting new number of workers to: 5\nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::343278755431:role/GlueRole\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: cf747cfa-d67c-4c3e-b7e3-f3614af26118\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.0\n--enable-glue-datacatalog true\nWaiting for session cf747cfa-d67c-4c3e-b7e3-f3614af26118 to get into ready status...\nSession cf747cfa-d67c-4c3e-b7e3-f3614af26118 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "args = getResolvedOptions(sys.argv, ['input_file','output_file'])\ninput_file = args['input_file']\noutput_file = args['output_file']",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "hits_df=spark.read.format(\"csv\").option(\"delimiter\",\"\\t\").option(\"header\", True).load(input_file)\n\ndef find_top_ref(df, hit_time_gmt, user_agent, ip, page_url):\n    topmost = df.filter((col(\"hit_time_gmt\") <= hit_time_gmt) & (col(\"user_agent\") == user_agent) & (col(\"ip\") == ip) & (col(\"page_url\") == page_url)).select(\"hit_time_gmt\", \"user_agent\", \"ip\", \"page_url\", \"referrer\")\n    referrer_list = hits_df.filter((col(\"hit_time_gmt\") <= hit_time_gmt) & (col(\"user_agent\") == user_agent) & (col(\"ip\") == ip) & (col(\"page_url\") == page_url)).select(\"referrer\").collect()\n    referrer=\"\"\n    if len(referrer_list)>0:\n        if len(referrer_list[0])>0:\n            referrer=referrer_list[0][0]\n    if referrer is not None:\n        if 'esshopzilla' not in referrer:\n            return referrer\n        else:\n            return find_top_ref(df,hit_time_gmt, user_agent, ip, referrer)\n    return referrer",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "order_df = hits_df.filter(\"pagename=='Order Complete'\")\nresult_dict = []\nfor order in order_df.collect():\n    result=find_top_ref(hits_df, order['hit_time_gmt'], order['user_agent'], order['ip'], order['page_url'])\n    if result and 'esshopzilla' not in result:\n        url = result.split(\".com\")[0].split(\".\")[-1] + \".com\"\n        keyword = result.split(\"?\")[-1].split(\"q=\")[1].split(\"&\")[0]\n        revenue=int(order['product_list'].split(\";\")[2]) * int(order['product_list'].split(\";\")[3])\n        result_dict.append({\"Search Engine Domain\": url, \"Search Keyword\":keyword, \"Revenue\": revenue})\nfinal_df=sc.parallelize(result_dict).toDF()\nfinal_df=final_df.groupBy(\"Search Engine Domain\",\"Search Keyword\").agg(sum(\"Revenue\").alias(\"Revenue\"))",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "final_df.write.mode(\"overwrite\").format(\"csv\").option(\"delimiter\",\"\\t\").option(\"header\", True).save(output_file)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}